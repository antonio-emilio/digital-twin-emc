# Copyright (c) 2019 Contributors to the Eclipse Foundation
#
# See the NOTICE file(s) distributed with this work for additional
# information regarding copyright ownership.
#
# This program and the accompanying materials are made available under the
# terms of the Eclipse Public License 2.0 which is available at
# http://www.eclipse.org/legal/epl-2.0
#
# SPDX-License-Identifier: EPL-2.0
version: '2.4'

networks:
  ditto-network:
    driver: bridge

services:
  mongodb:
    image: docker.io/mongo:5.0
    mem_limit: 256m
    restart: always
    networks:
      default:
        aliases:
          - mongodb
    command: mongod --storageEngine wiredTiger --noscripting
    user: mongodb
    ports:
      - 27017:27017
    environment:
       TZ: Europe/Berlin

  policies:
    image: docker.io/eclipse/ditto-policies:${DITTO_VERSION:-latest}
    mem_limit: 512m
    restart: always
    networks:
      default:
        aliases:
          - ditto-cluster
    environment:
      - TZ=Europe/Berlin
      - BIND_HOSTNAME=0.0.0.0
      # Set additional configuration options here appending JAVA_TOOL_OPTIONS: -Dditto.policies...
      - JAVA_TOOL_OPTIONS=-XX:ActiveProcessorCount=2 -XX:+ExitOnOutOfMemoryError -XX:+UseContainerSupport -XX:+UseStringDeduplication -Xss512k -XX:MaxRAMPercentage=50 -XX:+UseG1GC -XX:MaxGCPauseMillis=150 -Dpekko.coordinated-shutdown.exit-jvm=on -Dpekko.cluster.shutdown-after-unsuccessful-join-seed-nodes=180s -Dpekko.cluster.failure-detector.threshold=15.0 -Dpekko.cluster.failure-detector.expected-response-after=10s -Dpekko.cluster.failure-detector.acceptable-heartbeat-pause=20s -Dpekko.cluster.downing-provider-class=
      - MONGO_DB_HOSTNAME=mongodb
      # in order to write logs into a file you can enable this by setting the following env variable
      # the log file(s) can be found in /var/log/ditto directory on the host machine
      # - DITTO_LOGGING_FILE_APPENDER=true
    # only needed if DITTO_LOGGING_FILE_APPENDER is set
    # volumes:
    #  - ditto_log_files:/var/log/ditto
    healthcheck:
      test: curl --fail `hostname`:7626/alive || exit 1
      interval: 30s
      timeout: 15s
      retries: 4
      start_period: 120s

  things:
    image: docker.io/eclipse/ditto-things:${DITTO_VERSION:-latest}
    mem_limit: 512m
    restart: always
    networks:
      default:
        aliases:
          - ditto-cluster
    depends_on:
      - policies
    environment:
      - TZ=Europe/Berlin
      - BIND_HOSTNAME=0.0.0.0
      # Set additional configuration options here appending JAVA_TOOL_OPTIONS: -Dditto.things...
      - JAVA_TOOL_OPTIONS=-XX:ActiveProcessorCount=2 -XX:+ExitOnOutOfMemoryError -XX:+UseContainerSupport -XX:+UseStringDeduplication -Xss512k -XX:MaxRAMPercentage=50 -XX:+UseG1GC -XX:MaxGCPauseMillis=150 -Dpekko.coordinated-shutdown.exit-jvm=on -Dpekko.cluster.shutdown-after-unsuccessful-join-seed-nodes=180s -Dpekko.cluster.failure-detector.threshold=15.0 -Dpekko.cluster.failure-detector.expected-response-after=10s -Dpekko.cluster.failure-detector.acceptable-heartbeat-pause=20s -Dpekko.cluster.downing-provider-class=
      - MONGO_DB_HOSTNAME=mongodb
      # in order to write logs into a file you can enable this by setting the following env variable
      # the log file(s) can be found in /var/log/ditto directory on the host machine
      # - DITTO_LOGGING_FILE_APPENDER=true
    # only needed if DITTO_LOGGING_FILE_APPENDER is set
    # volumes:
    #  - ditto_log_files:/var/log/ditto
    healthcheck:
      test: curl --fail `hostname`:7626/alive || exit 1
      interval: 30s
      timeout: 15s
      retries: 4
      start_period: 120s

  things-search:
    image: docker.io/eclipse/ditto-things-search:${DITTO_VERSION:-latest}
    mem_limit: 512m
    restart: always
    networks:
      default:
        aliases:
          - ditto-cluster
    depends_on:
      - policies
    environment:
      - TZ=Europe/Berlin
      - BIND_HOSTNAME=0.0.0.0
      # Set additional configuration options here appending JAVA_TOOL_OPTIONS: -Dditto.search...
      - JAVA_TOOL_OPTIONS=-XX:ActiveProcessorCount=2 -XX:+ExitOnOutOfMemoryError -XX:+UseContainerSupport -XX:+UseStringDeduplication -Xss512k -XX:MaxRAMPercentage=50 -XX:+UseG1GC -XX:MaxGCPauseMillis=150 -Dpekko.coordinated-shutdown.exit-jvm=on -Dpekko.cluster.shutdown-after-unsuccessful-join-seed-nodes=180s -Dpekko.cluster.failure-detector.threshold=15.0 -Dpekko.cluster.failure-detector.expected-response-after=10s -Dpekko.cluster.failure-detector.acceptable-heartbeat-pause=20s -Dpekko.cluster.downing-provider-class=
      - MONGO_DB_HOSTNAME=mongodb
      # in order to write logs into a file you can enable this by setting the following env variable
      # the log file(s) can be found in /var/log/ditto directory on the host machine
      # - DITTO_LOGGING_FILE_APPENDER=true
    # only needed if DITTO_LOGGING_FILE_APPENDER is set
    # volumes:
    #  - ditto_log_files:/var/log/ditto
    healthcheck:
      test: curl --fail `hostname`:7626/alive || exit 1
      interval: 30s
      timeout: 15s
      retries: 4
      start_period: 120s

  connectivity:
    image: docker.io/eclipse/ditto-connectivity:${DITTO_VERSION:-latest}
    mem_limit: 768m
    restart: always
    networks:
      default:
        aliases:
          - ditto-cluster
    depends_on:
      - policies
    environment:
      - TZ=Europe/Berlin
      - BIND_HOSTNAME=0.0.0.0
      # if connections to rabbitmq broker are used, you might want to disable ExitOnOutOfMemoryError, because the amqp-client has a bug throwing OOM exceptions and causing a restart loop
      # Set additional configuration options here appending JAVA_TOOL_OPTIONS: -Dditto.connectivity...
      - JAVA_TOOL_OPTIONS=-XX:ActiveProcessorCount=2 -XX:+ExitOnOutOfMemoryError -XX:+UseContainerSupport -XX:+UseStringDeduplication -Xss512k -XX:MaxRAMPercentage=50 -XX:+UseG1GC -XX:MaxGCPauseMillis=150 -Dpekko.coordinated-shutdown.exit-jvm=on -Dpekko.cluster.shutdown-after-unsuccessful-join-seed-nodes=180s -Dpekko.cluster.failure-detector.threshold=15.0 -Dpekko.cluster.failure-detector.expected-response-after=10s -Dpekko.cluster.failure-detector.acceptable-heartbeat-pause=20s -Dpekko.cluster.downing-provider-class=
      - MONGO_DB_HOSTNAME=mongodb
      # in order to write logs into a file you can enable this by setting the following env variable
      # the log file(s) can be found in /var/log/ditto directory on the host machine
      # - DITTO_LOGGING_FILE_APPENDER=true
    # only needed if DITTO_LOGGING_FILE_APPENDER is set
    #volumes:
    #  - ditto_log_files:/var/log/ditto
    healthcheck:
      test: curl --fail `hostname`:7626/alive || exit 1
      interval: 30s
      timeout: 15s
      retries: 4
      start_period: 120s

  gateway:
    image: docker.io/eclipse/ditto-gateway:${DITTO_VERSION:-latest}
    mem_limit: 512m
    restart: always
    networks:
      default:
        aliases:
          - ditto-cluster
    depends_on:
      - policies
    ports:
      - "8081:8080"
    environment:
      - TZ=Europe/Berlin
      - BIND_HOSTNAME=0.0.0.0
      - ENABLE_PRE_AUTHENTICATION=true
      # Set additional configuration options here appending JAVA_TOOL_OPTIONS: -Dditto.gateway.authentication.devops.password=foobar -Dditto.gateway...
      - JAVA_TOOL_OPTIONS=-XX:ActiveProcessorCount=2 -XX:+ExitOnOutOfMemoryError -XX:+UseContainerSupport -XX:+UseStringDeduplication -Xss512k -XX:MaxRAMPercentage=50 -XX:+UseG1GC -XX:MaxGCPauseMillis=150 -Dpekko.coordinated-shutdown.exit-jvm=on -Dpekko.cluster.shutdown-after-unsuccessful-join-seed-nodes=180s -Dpekko.cluster.failure-detector.threshold=15.0 -Dpekko.cluster.failure-detector.expected-response-after=10s -Dpekko.cluster.failure-detector.acceptable-heartbeat-pause=20s -Dpekko.cluster.downing-provider-class=
      # in order to write logs into a file you can enable this by setting the following env variable
      # the log file(s) can be found in /var/log/ditto directory on the host machine
      # - DITTO_LOGGING_FILE_APPENDER=true
      # You may use the environment for setting the devops password
      #- DEVOPS_PASSWORD=foobar
    # only needed if DITTO_LOGGING_FILE_APPENDER is set
    # volumes:
    #  - ditto_log_files:/var/log/ditto
    healthcheck:
      test: curl --fail `hostname`:7626/alive || exit 1
      interval: 30s
      timeout: 15s
      retries: 4
      start_period: 120s

  ditto-ui:
    image: docker.io/eclipse/ditto-ui:${DITTO_VERSION:-latest}
    mem_limit: 32m
    restart: always

  swagger-ui:
    image: docker.io/swaggerapi/swagger-ui:v5.9.1
    mem_limit: 32m
    restart: always
    environment:
      - QUERY_CONFIG_ENABLED=true
    volumes:
       - ../../documentation/src/main/resources/openapi:/usr/share/nginx/html/openapi:ro
       - ../../documentation/src/main/resources/images:/usr/share/nginx/html/images:ro
       - ./swagger3-index.html:/usr/share/nginx/html/index.html:ro
    command: nginx -g 'daemon off;'

  nginx:
    image: docker.io/nginx:1.21-alpine
    mem_limit: 32m
    restart: always
    volumes:
       - ./nginx.conf:/etc/nginx/nginx.conf:ro
       - ./nginx.htpasswd:/etc/nginx/nginx.htpasswd:ro
       - ./nginx-cors.conf:/etc/nginx/nginx-cors.conf:ro
       - ./mime.types:/etc/nginx/mime.types:ro
       - ./index.html:/etc/nginx/html/index.html:ro
       - ../../documentation/src/main/resources/images:/etc/nginx/html/images:ro
       - ../../documentation/src/main/resources/wot:/etc/nginx/html/wot:ro
    ports:
      - "${DITTO_EXTERNAL_PORT:-8080}:80"
    depends_on:
      - gateway
      - swagger-ui
      
  mosquitto:
    hostname: mosquitto
    container_name: mosquitto
    image: eclipse-mosquitto
    restart: always
    networks:
      - ditto-network
      - default
    ports:
      - 1883 #default mqtt port
      - 9001 #default mqtt port for websockets
    volumes:
      - ./config:/mosquitto/config:rw
      - ./data:/mosquitto/data:rw
      - ./log:/mosquitto/log:rw
    
  grafana:
    image: grafana/grafana
    restart: always
    ports:
      - "3000:3000"
    networks:
      - ditto-network

  kafka0:
    image: confluentinc/cp-kafka:7.2.1
    hostname: kafka0
    container_name: kafka0
    restart: always
    ports:
      - "9092:9092"
      - "9997:9997"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka0:29092,PLAINTEXT_HOST://localhost:9092'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9997
      KAFKA_JMX_OPTS: -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=kafka0 -Dcom.sun.management.jmxremote.rmi.port=9997
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_NODE_ID: 1
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka0:29093'
      KAFKA_LISTENERS: 'PLAINTEXT://kafka0:29092,CONTROLLER://kafka0:29093,PLAINTEXT_HOST://0.0.0.0:9092'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_LOG_DIRS: '/tmp/kraft-combined-logs'
    volumes:
      - ./scripts/update_run.sh:/tmp/update_run.sh
    command: "bash -c 'if [ ! -f /tmp/update_run.sh ]; then echo \"ERROR: Did you forget the update_run.sh file that came with this docker-compose.yml file?\" && exit 1 ; else /tmp/update_run.sh && /etc/confluent/docker/run ; fi'"
    networks:
      - ditto-network
      - default

  kafka1:
    image: confluentinc/cp-kafka:7.2.1
    hostname: kafka1
    container_name: kafka1
    restart: always
    ports:
      - "9093:9092"
      - "9998:9998"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka1:29092,PLAINTEXT_HOST://localhost:9092'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9998
      KAFKA_JMX_OPTS: -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=kafka0 -Dcom.sun.management.jmxremote.rmi.port=9998
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_NODE_ID: 1
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka1:29093'
      KAFKA_LISTENERS: 'PLAINTEXT://kafka1:29092,CONTROLLER://kafka1:29093,PLAINTEXT_HOST://0.0.0.0:9092'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_LOG_DIRS: '/tmp/kraft-combined-logs'
    volumes:
      - ./scripts/update_run.sh:/tmp/update_run.sh
    command: "bash -c 'if [ ! -f /tmp/update_run.sh ]; then echo \"ERROR: Did you forget the update_run.sh file that came with this docker-compose.yml file?\" && exit 1 ; else /tmp/update_run.sh && /etc/confluent/docker/run ; fi'"
    networks:
      - ditto-network
      - default

  schemaregistry0:
    image: confluentinc/cp-schema-registry:7.2.1
    restart: always
    ports:
      - 8085:8085
    depends_on:
      - kafka0
    environment:
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: PLAINTEXT://kafka0:29092
      SCHEMA_REGISTRY_KAFKASTORE_SECURITY_PROTOCOL: PLAINTEXT
      SCHEMA_REGISTRY_HOST_NAME: schemaregistry0
      SCHEMA_REGISTRY_LISTENERS: http://schemaregistry0:8085

      SCHEMA_REGISTRY_SCHEMA_REGISTRY_INTER_INSTANCE_PROTOCOL: "http"
      SCHEMA_REGISTRY_LOG4J_ROOT_LOGLEVEL: INFO
      SCHEMA_REGISTRY_KAFKASTORE_TOPIC: _schemas
    networks:
      - ditto-network
      - default

  schemaregistry1:
    image: confluentinc/cp-schema-registry:7.2.1
    restart: always
    ports:
      - 18085:8085
    depends_on:
      - kafka1
    environment:
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: PLAINTEXT://kafka1:29092
      SCHEMA_REGISTRY_KAFKASTORE_SECURITY_PROTOCOL: PLAINTEXT
      SCHEMA_REGISTRY_HOST_NAME: schemaregistry1
      SCHEMA_REGISTRY_LISTENERS: http://schemaregistry1:8085

      SCHEMA_REGISTRY_SCHEMA_REGISTRY_INTER_INSTANCE_PROTOCOL: "http"
      SCHEMA_REGISTRY_LOG4J_ROOT_LOGLEVEL: INFO
      SCHEMA_REGISTRY_KAFKASTORE_TOPIC: _schemas
    networks:
      - ditto-network
      - default

  kafka-connect0:
    image: confluentinc/cp-kafka-connect:7.2.1
    restart: always
    ports:
      - 8083:8083
    depends_on:
      - kafka0
      - schemaregistry0
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka0:29092
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: _connect_configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_TOPIC: _connect_offset
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_TOPIC: _connect_status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: http://schemaregistry0:8085
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schemaregistry0:8085
      CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_REST_ADVERTISED_HOST_NAME: kafka-connect0
      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components"
    networks:
      - ditto-network
      - default

  kafka-init-topics:
    image: confluentinc/cp-kafka:7.2.1
    volumes:
       - ./data/message.json:/data/message.json
    depends_on:
      - kafka1
    command: "bash -c 'echo Waiting for Kafka to be ready... && \
               cub kafka-ready -b kafka1:29092 1 30 && \
               kafka-topics --create --topic second.users --partitions 3 --replication-factor 1 --if-not-exists --bootstrap-server kafka1:29092 && \
               kafka-topics --create --topic second.messages --partitions 2 --replication-factor 1 --if-not-exists --bootstrap-server kafka1:29092 && \
               kafka-topics --create --topic first.messages --partitions 2 --replication-factor 1 --if-not-exists --bootstrap-server kafka0:29092 && \
               kafka-console-producer --bootstrap-server kafka1:29092 -topic second.users < /data/message.json'"
    networks:
      - ditto-network
      - default

  influxdb:
    image: influxdb:latest
    restart: always
    ports:
      - '8086:8086'
    volumes:
      - influxdb-storage:/var/lib/influxdb
    environment:
      - INFLUXDB_DB=db0
      - INFLUXDB_ADMIN_USER=${INFLUXDB_USERNAME}
      - INFLUXDB_ADMIN_PASSWORD=${INFLUXDB_PASSWORD}
      
  chronograf:
    image: chronograf:latest
    restart: always
    ports:
      - '127.0.0.1:8888:8888'
    volumes:
      - chronograf-storage:/var/lib/chronograf
    depends_on:
      - influxdb
    environment:
      - INFLUXDB_URL=http://influxdb:8086
      - INFLUXDB_USERNAME=${INFLUXDB_USERNAME}
      - INFLUXDB_PASSWORD=${INFLUXDB_PASSWORD}

  telegraf:
    image: docker.io/telegraf:latest
    container_name: telegraf
    restart: always
    depends_on:
      - influxdb
      - kafka0
      - kafka1
      - kafka-init-topics
      - kafka-connect0
      - schemaregistry1
      - schemaregistry0
    ports:
      - '8125:8125'
    depends_on:
      - influxdb
    volumes:
      - ./telegraf.conf:/etc/telegraf/telegraf.conf:ro
    networks:
      - ditto-network
      - default

volumes:
  influxdb-storage:
  chronograf-storage:
  ditto_log_files:
    driver: local
    driver_opts:
      type: none
      device: /var/log/ditto
      o: bind,uid=1000,gid=1000
